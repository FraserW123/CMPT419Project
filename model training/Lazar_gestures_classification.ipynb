{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "99oAbvtd4hXp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import matplotlib.image as mpimg\n",
        "from scipy import ndimage\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the file path\n",
        "data_path = \"/content/drive/My Drive/Cmpt_419_Project/dataset_green/\"\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "learning_rate = 0.0002\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EJQskng4ivN",
        "outputId": "b9f78f91-7ef6-4a2e-e6b6-aae41c335b04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zFENbM04hXv"
      },
      "outputs": [],
      "source": [
        "data_path = 'dataset_green/'\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "learning_rate = 0.0002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ycGbjfr4hXw",
        "outputId": "b8513a7a-94fb-4129-f9fa-6783d7b5f945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 88 images from 3 classes.\n",
            "Dataset size:  88\n",
            "Training set size:  70\n",
            "Validation set size:  18\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "from image_dataloader import GestureImageDataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),  # Rotate within Â±15 degrees\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Shift up to 10%\n",
        "    transforms.RandomResizedCrop(28, scale=(0.9, 1.1)),  # Slight zoom in/out\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),  # Converts to (C, H, W) where C=1 for grayscale\n",
        "])\n",
        "\n",
        "\n",
        "dataset = GestureImageDataset(data_path, transform=transform)\n",
        "\n",
        "print(\"Dataset size: \", len(dataset))\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(\"Training set size: \", len(train_dataset))\n",
        "print(\"Validation set size: \", len(val_dataset))\n",
        "\n",
        "# Create the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pmxzWNCX4hXy"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UHc-ugbR4hXz"
      },
      "outputs": [],
      "source": [
        "# Create a Convolutional Neural Network\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1000)  # Corrected input size (3136)\n",
        "        self.fc2 = nn.Linear(1000, 3)  # Assuming 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)  # (batch, 32, 14, 14)\n",
        "        out = self.layer2(out)  # (batch, 64, 7, 7)\n",
        "        out = out.view(out.size(0), -1)  # Flatten to (batch, 3136)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Test with a random input tensor\n",
        "# model = ConvNet()\n",
        "# x = torch.randn(8, 1, 28, 28)  # Batch size = 8, Grayscale image (1, 28, 28)\n",
        "# output = model(x)\n",
        "# print(output.shape)  # Expected: (8, 26)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6kpaE_tG4hX0"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5O8GR44hX1",
        "outputId": "6892b63e-353b-49ca-a0a7-9c6f9c57160a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] - Train Loss: 1.1018, Train Accuracy: 27.14% - Validation Loss: 1.1018, Validation Accuracy: 27.78%\n",
            "Epoch [2/100] - Train Loss: 1.1114, Train Accuracy: 30.00% - Validation Loss: 1.1114, Validation Accuracy: 33.33%\n",
            "Epoch [3/100] - Train Loss: 1.1202, Train Accuracy: 31.43% - Validation Loss: 1.1202, Validation Accuracy: 38.89%\n",
            "Epoch [4/100] - Train Loss: 1.1119, Train Accuracy: 38.57% - Validation Loss: 1.1119, Validation Accuracy: 27.78%\n",
            "Epoch [5/100] - Train Loss: 1.1057, Train Accuracy: 38.57% - Validation Loss: 1.1057, Validation Accuracy: 27.78%\n",
            "Epoch [6/100] - Train Loss: 1.1041, Train Accuracy: 31.43% - Validation Loss: 1.1041, Validation Accuracy: 33.33%\n",
            "Epoch [7/100] - Train Loss: 1.0919, Train Accuracy: 34.29% - Validation Loss: 1.0919, Validation Accuracy: 38.89%\n",
            "Epoch [8/100] - Train Loss: 1.0896, Train Accuracy: 37.14% - Validation Loss: 1.0896, Validation Accuracy: 33.33%\n",
            "Epoch [9/100] - Train Loss: 1.1481, Train Accuracy: 28.57% - Validation Loss: 1.1481, Validation Accuracy: 22.22%\n",
            "Epoch [10/100] - Train Loss: 1.1162, Train Accuracy: 40.00% - Validation Loss: 1.1162, Validation Accuracy: 27.78%\n",
            "Epoch [11/100] - Train Loss: 1.1311, Train Accuracy: 34.29% - Validation Loss: 1.1311, Validation Accuracy: 27.78%\n",
            "Epoch [12/100] - Train Loss: 1.0876, Train Accuracy: 34.29% - Validation Loss: 1.0876, Validation Accuracy: 27.78%\n",
            "Epoch [13/100] - Train Loss: 1.0842, Train Accuracy: 40.00% - Validation Loss: 1.0842, Validation Accuracy: 38.89%\n",
            "Epoch [14/100] - Train Loss: 1.0675, Train Accuracy: 34.29% - Validation Loss: 1.0675, Validation Accuracy: 38.89%\n",
            "Epoch [15/100] - Train Loss: 1.0658, Train Accuracy: 35.71% - Validation Loss: 1.0658, Validation Accuracy: 50.00%\n",
            "Epoch [16/100] - Train Loss: 1.0942, Train Accuracy: 40.00% - Validation Loss: 1.0942, Validation Accuracy: 27.78%\n",
            "Epoch [17/100] - Train Loss: 1.1057, Train Accuracy: 41.43% - Validation Loss: 1.1057, Validation Accuracy: 27.78%\n",
            "Epoch [18/100] - Train Loss: 1.0905, Train Accuracy: 40.00% - Validation Loss: 1.0905, Validation Accuracy: 38.89%\n",
            "Epoch [19/100] - Train Loss: 1.0918, Train Accuracy: 44.29% - Validation Loss: 1.0918, Validation Accuracy: 27.78%\n",
            "Epoch [20/100] - Train Loss: 1.0871, Train Accuracy: 44.29% - Validation Loss: 1.0871, Validation Accuracy: 33.33%\n",
            "Epoch [21/100] - Train Loss: 1.0542, Train Accuracy: 40.00% - Validation Loss: 1.0542, Validation Accuracy: 61.11%\n",
            "Epoch [22/100] - Train Loss: 1.0704, Train Accuracy: 48.57% - Validation Loss: 1.0704, Validation Accuracy: 50.00%\n",
            "Epoch [23/100] - Train Loss: 1.0952, Train Accuracy: 45.71% - Validation Loss: 1.0952, Validation Accuracy: 55.56%\n",
            "Epoch [24/100] - Train Loss: 1.0572, Train Accuracy: 48.57% - Validation Loss: 1.0572, Validation Accuracy: 38.89%\n",
            "Epoch [25/100] - Train Loss: 1.0390, Train Accuracy: 47.14% - Validation Loss: 1.0390, Validation Accuracy: 50.00%\n",
            "Epoch [26/100] - Train Loss: 1.0335, Train Accuracy: 41.43% - Validation Loss: 1.0335, Validation Accuracy: 50.00%\n",
            "Epoch [27/100] - Train Loss: 1.0344, Train Accuracy: 47.14% - Validation Loss: 1.0344, Validation Accuracy: 66.67%\n",
            "Epoch [28/100] - Train Loss: 1.0635, Train Accuracy: 45.71% - Validation Loss: 1.0635, Validation Accuracy: 55.56%\n",
            "Epoch [29/100] - Train Loss: 1.0127, Train Accuracy: 50.00% - Validation Loss: 1.0127, Validation Accuracy: 61.11%\n",
            "Epoch [30/100] - Train Loss: 1.0513, Train Accuracy: 50.00% - Validation Loss: 1.0513, Validation Accuracy: 50.00%\n",
            "Epoch [31/100] - Train Loss: 1.0349, Train Accuracy: 44.29% - Validation Loss: 1.0349, Validation Accuracy: 50.00%\n",
            "Epoch [32/100] - Train Loss: 0.9876, Train Accuracy: 52.86% - Validation Loss: 0.9876, Validation Accuracy: 61.11%\n",
            "Epoch [33/100] - Train Loss: 1.0474, Train Accuracy: 42.86% - Validation Loss: 1.0474, Validation Accuracy: 38.89%\n",
            "Epoch [34/100] - Train Loss: 1.0168, Train Accuracy: 48.57% - Validation Loss: 1.0168, Validation Accuracy: 55.56%\n",
            "Epoch [35/100] - Train Loss: 1.0029, Train Accuracy: 42.86% - Validation Loss: 1.0029, Validation Accuracy: 55.56%\n",
            "Epoch [36/100] - Train Loss: 1.0132, Train Accuracy: 48.57% - Validation Loss: 1.0132, Validation Accuracy: 44.44%\n",
            "Epoch [37/100] - Train Loss: 0.9757, Train Accuracy: 44.29% - Validation Loss: 0.9757, Validation Accuracy: 72.22%\n",
            "Epoch [38/100] - Train Loss: 1.0170, Train Accuracy: 57.14% - Validation Loss: 1.0170, Validation Accuracy: 50.00%\n",
            "Epoch [39/100] - Train Loss: 0.9680, Train Accuracy: 51.43% - Validation Loss: 0.9680, Validation Accuracy: 50.00%\n",
            "Epoch [40/100] - Train Loss: 1.0022, Train Accuracy: 60.00% - Validation Loss: 1.0022, Validation Accuracy: 50.00%\n",
            "Epoch [41/100] - Train Loss: 0.9819, Train Accuracy: 61.43% - Validation Loss: 0.9819, Validation Accuracy: 61.11%\n",
            "Epoch [42/100] - Train Loss: 0.9733, Train Accuracy: 67.14% - Validation Loss: 0.9733, Validation Accuracy: 72.22%\n",
            "Epoch [43/100] - Train Loss: 0.9607, Train Accuracy: 75.71% - Validation Loss: 0.9607, Validation Accuracy: 55.56%\n",
            "Epoch [44/100] - Train Loss: 0.9842, Train Accuracy: 52.86% - Validation Loss: 0.9842, Validation Accuracy: 44.44%\n",
            "Epoch [45/100] - Train Loss: 0.9499, Train Accuracy: 55.71% - Validation Loss: 0.9499, Validation Accuracy: 50.00%\n",
            "Epoch [46/100] - Train Loss: 0.8932, Train Accuracy: 61.43% - Validation Loss: 0.8932, Validation Accuracy: 66.67%\n",
            "Epoch [47/100] - Train Loss: 0.9889, Train Accuracy: 52.86% - Validation Loss: 0.9889, Validation Accuracy: 50.00%\n",
            "Epoch [48/100] - Train Loss: 0.9812, Train Accuracy: 58.57% - Validation Loss: 0.9812, Validation Accuracy: 55.56%\n",
            "Epoch [49/100] - Train Loss: 0.9555, Train Accuracy: 57.14% - Validation Loss: 0.9555, Validation Accuracy: 44.44%\n",
            "Epoch [50/100] - Train Loss: 0.9258, Train Accuracy: 57.14% - Validation Loss: 0.9258, Validation Accuracy: 77.78%\n",
            "Epoch [51/100] - Train Loss: 0.8488, Train Accuracy: 71.43% - Validation Loss: 0.8488, Validation Accuracy: 66.67%\n",
            "Epoch [52/100] - Train Loss: 0.8433, Train Accuracy: 60.00% - Validation Loss: 0.8433, Validation Accuracy: 72.22%\n",
            "Epoch [53/100] - Train Loss: 0.8423, Train Accuracy: 61.43% - Validation Loss: 0.8423, Validation Accuracy: 66.67%\n",
            "Epoch [54/100] - Train Loss: 0.8341, Train Accuracy: 65.71% - Validation Loss: 0.8341, Validation Accuracy: 66.67%\n",
            "Epoch [55/100] - Train Loss: 0.8068, Train Accuracy: 65.71% - Validation Loss: 0.8068, Validation Accuracy: 77.78%\n",
            "Epoch [56/100] - Train Loss: 0.7998, Train Accuracy: 64.29% - Validation Loss: 0.7998, Validation Accuracy: 88.89%\n",
            "Epoch [57/100] - Train Loss: 0.7858, Train Accuracy: 82.86% - Validation Loss: 0.7858, Validation Accuracy: 77.78%\n",
            "Epoch [58/100] - Train Loss: 0.7466, Train Accuracy: 68.57% - Validation Loss: 0.7466, Validation Accuracy: 100.00%\n",
            "Epoch [59/100] - Train Loss: 0.7878, Train Accuracy: 74.29% - Validation Loss: 0.7878, Validation Accuracy: 88.89%\n",
            "Epoch [60/100] - Train Loss: 0.7995, Train Accuracy: 78.57% - Validation Loss: 0.7995, Validation Accuracy: 72.22%\n",
            "Epoch [61/100] - Train Loss: 0.7587, Train Accuracy: 78.57% - Validation Loss: 0.7587, Validation Accuracy: 88.89%\n",
            "Epoch [62/100] - Train Loss: 0.7325, Train Accuracy: 85.71% - Validation Loss: 0.7325, Validation Accuracy: 83.33%\n",
            "Epoch [63/100] - Train Loss: 0.6798, Train Accuracy: 82.86% - Validation Loss: 0.6798, Validation Accuracy: 88.89%\n",
            "Epoch [64/100] - Train Loss: 0.7508, Train Accuracy: 78.57% - Validation Loss: 0.7508, Validation Accuracy: 72.22%\n",
            "Epoch [65/100] - Train Loss: 0.6731, Train Accuracy: 70.00% - Validation Loss: 0.6731, Validation Accuracy: 77.78%\n",
            "Epoch [66/100] - Train Loss: 0.7032, Train Accuracy: 72.86% - Validation Loss: 0.7032, Validation Accuracy: 72.22%\n",
            "Epoch [67/100] - Train Loss: 0.6598, Train Accuracy: 74.29% - Validation Loss: 0.6598, Validation Accuracy: 77.78%\n",
            "Epoch [68/100] - Train Loss: 0.6444, Train Accuracy: 75.71% - Validation Loss: 0.6444, Validation Accuracy: 77.78%\n",
            "Epoch [69/100] - Train Loss: 0.7276, Train Accuracy: 81.43% - Validation Loss: 0.7276, Validation Accuracy: 77.78%\n",
            "Epoch [70/100] - Train Loss: 0.6585, Train Accuracy: 71.43% - Validation Loss: 0.6585, Validation Accuracy: 66.67%\n",
            "Epoch [71/100] - Train Loss: 0.5492, Train Accuracy: 82.86% - Validation Loss: 0.5492, Validation Accuracy: 94.44%\n",
            "Epoch [72/100] - Train Loss: 0.5908, Train Accuracy: 82.86% - Validation Loss: 0.5908, Validation Accuracy: 83.33%\n",
            "Epoch [73/100] - Train Loss: 0.5193, Train Accuracy: 78.57% - Validation Loss: 0.5193, Validation Accuracy: 94.44%\n",
            "Epoch [74/100] - Train Loss: 0.5466, Train Accuracy: 82.86% - Validation Loss: 0.5466, Validation Accuracy: 88.89%\n",
            "Epoch [75/100] - Train Loss: 0.5421, Train Accuracy: 80.00% - Validation Loss: 0.5421, Validation Accuracy: 94.44%\n",
            "Epoch [76/100] - Train Loss: 0.4862, Train Accuracy: 87.14% - Validation Loss: 0.4862, Validation Accuracy: 94.44%\n",
            "Epoch [77/100] - Train Loss: 0.4548, Train Accuracy: 85.71% - Validation Loss: 0.4548, Validation Accuracy: 94.44%\n",
            "Epoch [78/100] - Train Loss: 0.4997, Train Accuracy: 88.57% - Validation Loss: 0.4997, Validation Accuracy: 88.89%\n",
            "Epoch [79/100] - Train Loss: 0.5105, Train Accuracy: 87.14% - Validation Loss: 0.5105, Validation Accuracy: 88.89%\n",
            "Epoch [80/100] - Train Loss: 0.4975, Train Accuracy: 78.57% - Validation Loss: 0.4975, Validation Accuracy: 88.89%\n",
            "Epoch [81/100] - Train Loss: 0.4102, Train Accuracy: 84.29% - Validation Loss: 0.4102, Validation Accuracy: 94.44%\n",
            "Epoch [82/100] - Train Loss: 0.3831, Train Accuracy: 87.14% - Validation Loss: 0.3831, Validation Accuracy: 100.00%\n",
            "Epoch [83/100] - Train Loss: 0.4027, Train Accuracy: 92.86% - Validation Loss: 0.4027, Validation Accuracy: 100.00%\n",
            "Epoch [84/100] - Train Loss: 0.5137, Train Accuracy: 90.00% - Validation Loss: 0.5137, Validation Accuracy: 94.44%\n",
            "Epoch [85/100] - Train Loss: 0.3975, Train Accuracy: 92.86% - Validation Loss: 0.3975, Validation Accuracy: 94.44%\n",
            "Epoch [86/100] - Train Loss: 0.4378, Train Accuracy: 91.43% - Validation Loss: 0.4378, Validation Accuracy: 94.44%\n",
            "Epoch [87/100] - Train Loss: 0.3060, Train Accuracy: 90.00% - Validation Loss: 0.3060, Validation Accuracy: 100.00%\n",
            "Epoch [88/100] - Train Loss: 0.3824, Train Accuracy: 84.29% - Validation Loss: 0.3824, Validation Accuracy: 88.89%\n",
            "Epoch [89/100] - Train Loss: 0.3215, Train Accuracy: 90.00% - Validation Loss: 0.3215, Validation Accuracy: 100.00%\n",
            "Epoch [90/100] - Train Loss: 0.3999, Train Accuracy: 90.00% - Validation Loss: 0.3999, Validation Accuracy: 94.44%\n",
            "Epoch [91/100] - Train Loss: 0.3688, Train Accuracy: 88.57% - Validation Loss: 0.3688, Validation Accuracy: 94.44%\n",
            "Epoch [92/100] - Train Loss: 0.3250, Train Accuracy: 92.86% - Validation Loss: 0.3250, Validation Accuracy: 88.89%\n",
            "Epoch [93/100] - Train Loss: 0.3487, Train Accuracy: 91.43% - Validation Loss: 0.3487, Validation Accuracy: 94.44%\n",
            "Epoch [94/100] - Train Loss: 0.3569, Train Accuracy: 81.43% - Validation Loss: 0.3569, Validation Accuracy: 88.89%\n",
            "Epoch [95/100] - Train Loss: 0.3728, Train Accuracy: 90.00% - Validation Loss: 0.3728, Validation Accuracy: 94.44%\n",
            "Epoch [96/100] - Train Loss: 0.2822, Train Accuracy: 88.57% - Validation Loss: 0.2822, Validation Accuracy: 94.44%\n",
            "Epoch [97/100] - Train Loss: 0.2337, Train Accuracy: 87.14% - Validation Loss: 0.2337, Validation Accuracy: 100.00%\n",
            "Epoch [98/100] - Train Loss: 0.3006, Train Accuracy: 91.43% - Validation Loss: 0.3006, Validation Accuracy: 94.44%\n",
            "Epoch [99/100] - Train Loss: 0.2526, Train Accuracy: 91.43% - Validation Loss: 0.2526, Validation Accuracy: 100.00%\n",
            "Epoch [100/100] - Train Loss: 0.2178, Train Accuracy: 90.00% - Validation Loss: 0.2178, Validation Accuracy: 94.44%\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        # Compute training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    # Compute overall training accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    train_acc.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(val_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            # Compute validation accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    val_acc.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
        "          f'Train Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}% - '\n",
        "          f'Validation Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model after training is complete\n",
        "final_model_path = \"/content/drive/MyDrive/Cmpt_419_Project/arm_gesture_model_100.pth\"\n",
        "torch.save(model.state_dict(), final_model_path)\n"
      ],
      "metadata": {
        "id": "zua7p_3w_BAF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG7dASAi4hX3",
        "outputId": "b011d3c3-fb07-4ac1-88ba-ed8939f361c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(model, image_path, device):\n",
        "    \"\"\"\n",
        "    Given a trained model and an image path, predict the label of the image.\n",
        "    \"\"\"\n",
        "    # Define the same transformations used during training\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(),  # Ensure image is grayscale (if applicable)\n",
        "        transforms.Resize((28, 28)),  # Resize to match model input size\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "    ])\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension: (1, 1, 28, 28)\n",
        "\n",
        "    # Move to device (CPU/GPU)\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient calculation for inference\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)  # Get predicted class\n",
        "\n",
        "    return predicted.item()  # Return the predicted label\n",
        "\n",
        "# Example Usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "#image_path = \"unused_data/right6.jpg\"  # Replace with your image path\n",
        "image_path = \"right6.jpg\"  # Replace with your image path\n",
        "predicted_label = predict_image(model, image_path, device)\n",
        "\n",
        "print(f\"Predicted label: {predicted_label}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}