{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y mediapipe\n",
        "!pip install mediapipe==0.10.20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N27fq3-ik9N",
        "outputId": "6b3788e7-a1ab-4def-987e-d71677fd5bda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: mediapipe 0.10.20\n",
            "Uninstalling mediapipe-0.10.20:\n",
            "  Successfully uninstalled mediapipe-0.10.20\n",
            "Collecting mediapipe==0.10.20\n",
            "  Using cached mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (4.25.6)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.20) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.20) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.20) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.20) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.20) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.20) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.20) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.20) (1.17.0)\n",
            "Using cached mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.10.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMef4zcjjspg",
        "outputId": "e86c58e9-bd5c-4393-ff8d-c52a9dc653e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "data_path = \"/content/drive/My Drive/Cmpt_419_Project/dataset_green/\"\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "learning_rate = 0.0002\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "RgCfeXg_nC5H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MediaPipe Pose initialization\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# 1. Extract Landmarks from Images\n",
        "def extract_arm_landmarks(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\n",
        "        results = pose.process(image_rgb)\n",
        "        if not results.pose_landmarks:\n",
        "            return None\n",
        "\n",
        "        # Extract arm landmarks (left and right shoulders, elbows, wrists)\n",
        "        landmark_indices = [11, 12, 13, 14, 15, 16]  # MediaPipe pose landmarks\n",
        "        landmarks = []\n",
        "        for idx in landmark_indices:\n",
        "            lm = results.pose_landmarks.landmark[idx]\n",
        "            landmarks.extend([lm.x, lm.y, lm.z])  # x, y, z coordinates\n",
        "\n",
        "        return np.array(landmarks)\n"
      ],
      "metadata": {
        "id": "k7sEjzfRs8xx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process dataset and save landmarks\n",
        "def process_dataset(data_path):\n",
        "    all_landmarks = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Use the same label mapping as GestureImageDataset\n",
        "    label_map = {\"left\": 0, \"right\": 1, \"stop\": 2}\n",
        "\n",
        "    for class_name in label_map.keys():  # Only process defined classes\n",
        "        class_dir = os.path.join(data_path, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, img_name)\n",
        "                landmarks = extract_arm_landmarks(img_path)\n",
        "                if landmarks is not None:\n",
        "                    all_landmarks.append(landmarks)\n",
        "                    all_labels.append(label_map[class_name])  # Use predefined label\n",
        "\n",
        "    return np.array(all_landmarks), np.array(all_labels)\n",
        "\n",
        "# Run processing\n",
        "landmarks, labels = process_dataset(data_path)\n",
        "print(f\"Processed {len(landmarks)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mo-PpZitB_x",
        "outputId": "c8f793d2-c231-40d6-9cbc-ea956b712ca3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 88 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create PyTorch Dataset\n",
        "class ArmLandmarkDataset(Dataset):\n",
        "    def __init__(self, landmarks, labels):\n",
        "        self.landmarks = landmarks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.landmarks[idx], dtype=torch.float32),\n",
        "                torch.tensor(self.labels[idx], dtype=torch.long))\n",
        "\n",
        "# Create dataset and split\n",
        "dataset = ArmLandmarkDataset(landmarks, labels)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "q_LkADem2Ip5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define Model Architecture\n",
        "class ArmGestureNet(nn.Module):\n",
        "    def __init__(self, input_size=18, num_classes=3):\n",
        "        super(ArmGestureNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.batchnorm = nn.BatchNorm1d(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lThcvqu52rAx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = ArmGestureNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "tC1WfYTu2rHl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Print statistics\n",
        "    train_acc = 100 * correct / total\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
        "          f'Train Loss: {running_loss/len(train_loader):.4f}, Acc: {train_acc:.2f}% | '\n",
        "          f'Val Loss: {val_loss/len(val_loader):.4f}, Acc: {val_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAzNpPUc2rPZ",
        "outputId": "290ffaae-7d14-4ed1-ff56-2ea98f425d73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Train Loss: 1.1022, Acc: 35.71% | Val Loss: 1.1023, Acc: 33.33%\n",
            "Epoch [2/100] Train Loss: 1.0725, Acc: 45.71% | Val Loss: 1.1018, Acc: 33.33%\n",
            "Epoch [3/100] Train Loss: 1.0468, Acc: 44.29% | Val Loss: 1.1007, Acc: 33.33%\n",
            "Epoch [4/100] Train Loss: 1.0379, Acc: 52.86% | Val Loss: 1.0993, Acc: 33.33%\n",
            "Epoch [5/100] Train Loss: 0.9630, Acc: 57.14% | Val Loss: 1.0972, Acc: 33.33%\n",
            "Epoch [6/100] Train Loss: 0.9814, Acc: 70.00% | Val Loss: 1.0941, Acc: 38.89%\n",
            "Epoch [7/100] Train Loss: 0.9037, Acc: 78.57% | Val Loss: 1.0903, Acc: 44.44%\n",
            "Epoch [8/100] Train Loss: 0.8782, Acc: 85.71% | Val Loss: 1.0852, Acc: 61.11%\n",
            "Epoch [9/100] Train Loss: 0.8315, Acc: 84.29% | Val Loss: 1.0781, Acc: 61.11%\n",
            "Epoch [10/100] Train Loss: 0.8821, Acc: 95.71% | Val Loss: 1.0686, Acc: 61.11%\n",
            "Epoch [11/100] Train Loss: 0.7865, Acc: 92.86% | Val Loss: 1.0565, Acc: 61.11%\n",
            "Epoch [12/100] Train Loss: 0.7849, Acc: 90.00% | Val Loss: 1.0416, Acc: 61.11%\n",
            "Epoch [13/100] Train Loss: 0.7733, Acc: 94.29% | Val Loss: 1.0232, Acc: 66.67%\n",
            "Epoch [14/100] Train Loss: 0.7249, Acc: 95.71% | Val Loss: 1.0020, Acc: 72.22%\n",
            "Epoch [15/100] Train Loss: 0.7083, Acc: 97.14% | Val Loss: 0.9771, Acc: 77.78%\n",
            "Epoch [16/100] Train Loss: 0.7162, Acc: 98.57% | Val Loss: 0.9480, Acc: 83.33%\n",
            "Epoch [17/100] Train Loss: 0.7091, Acc: 95.71% | Val Loss: 0.9149, Acc: 88.89%\n",
            "Epoch [18/100] Train Loss: 0.6487, Acc: 98.57% | Val Loss: 0.8773, Acc: 88.89%\n",
            "Epoch [19/100] Train Loss: 0.6577, Acc: 98.57% | Val Loss: 0.8363, Acc: 94.44%\n",
            "Epoch [20/100] Train Loss: 0.6023, Acc: 98.57% | Val Loss: 0.7891, Acc: 100.00%\n",
            "Epoch [21/100] Train Loss: 0.5506, Acc: 100.00% | Val Loss: 0.7416, Acc: 100.00%\n",
            "Epoch [22/100] Train Loss: 0.5692, Acc: 98.57% | Val Loss: 0.6943, Acc: 100.00%\n",
            "Epoch [23/100] Train Loss: 0.5578, Acc: 100.00% | Val Loss: 0.6416, Acc: 100.00%\n",
            "Epoch [24/100] Train Loss: 0.5441, Acc: 98.57% | Val Loss: 0.5928, Acc: 100.00%\n",
            "Epoch [25/100] Train Loss: 0.4982, Acc: 100.00% | Val Loss: 0.5477, Acc: 100.00%\n",
            "Epoch [26/100] Train Loss: 0.4806, Acc: 98.57% | Val Loss: 0.5027, Acc: 100.00%\n",
            "Epoch [27/100] Train Loss: 0.4670, Acc: 97.14% | Val Loss: 0.4672, Acc: 100.00%\n",
            "Epoch [28/100] Train Loss: 0.4686, Acc: 98.57% | Val Loss: 0.4339, Acc: 100.00%\n",
            "Epoch [29/100] Train Loss: 0.4755, Acc: 97.14% | Val Loss: 0.3984, Acc: 100.00%\n",
            "Epoch [30/100] Train Loss: 0.4785, Acc: 98.57% | Val Loss: 0.3670, Acc: 100.00%\n",
            "Epoch [31/100] Train Loss: 0.4223, Acc: 100.00% | Val Loss: 0.3381, Acc: 100.00%\n",
            "Epoch [32/100] Train Loss: 0.3183, Acc: 98.57% | Val Loss: 0.3194, Acc: 100.00%\n",
            "Epoch [33/100] Train Loss: 0.3452, Acc: 100.00% | Val Loss: 0.3020, Acc: 100.00%\n",
            "Epoch [34/100] Train Loss: 0.3520, Acc: 100.00% | Val Loss: 0.2831, Acc: 100.00%\n",
            "Epoch [35/100] Train Loss: 0.3508, Acc: 98.57% | Val Loss: 0.2674, Acc: 100.00%\n",
            "Epoch [36/100] Train Loss: 0.2991, Acc: 100.00% | Val Loss: 0.2529, Acc: 100.00%\n",
            "Epoch [37/100] Train Loss: 0.2602, Acc: 98.57% | Val Loss: 0.2454, Acc: 100.00%\n",
            "Epoch [38/100] Train Loss: 0.3168, Acc: 98.57% | Val Loss: 0.2320, Acc: 100.00%\n",
            "Epoch [39/100] Train Loss: 0.2338, Acc: 100.00% | Val Loss: 0.2258, Acc: 100.00%\n",
            "Epoch [40/100] Train Loss: 0.2505, Acc: 100.00% | Val Loss: 0.2123, Acc: 100.00%\n",
            "Epoch [41/100] Train Loss: 0.2005, Acc: 100.00% | Val Loss: 0.2021, Acc: 100.00%\n",
            "Epoch [42/100] Train Loss: 0.1932, Acc: 100.00% | Val Loss: 0.1981, Acc: 100.00%\n",
            "Epoch [43/100] Train Loss: 0.2014, Acc: 100.00% | Val Loss: 0.1877, Acc: 100.00%\n",
            "Epoch [44/100] Train Loss: 0.2077, Acc: 100.00% | Val Loss: 0.1749, Acc: 100.00%\n",
            "Epoch [45/100] Train Loss: 0.3595, Acc: 98.57% | Val Loss: 0.1674, Acc: 100.00%\n",
            "Epoch [46/100] Train Loss: 0.1937, Acc: 100.00% | Val Loss: 0.1580, Acc: 100.00%\n",
            "Epoch [47/100] Train Loss: 0.1594, Acc: 100.00% | Val Loss: 0.1441, Acc: 100.00%\n",
            "Epoch [48/100] Train Loss: 0.1608, Acc: 100.00% | Val Loss: 0.1372, Acc: 100.00%\n",
            "Epoch [49/100] Train Loss: 0.1651, Acc: 100.00% | Val Loss: 0.1303, Acc: 100.00%\n",
            "Epoch [50/100] Train Loss: 0.3506, Acc: 97.14% | Val Loss: 0.1232, Acc: 100.00%\n",
            "Epoch [51/100] Train Loss: 0.1457, Acc: 100.00% | Val Loss: 0.1198, Acc: 100.00%\n",
            "Epoch [52/100] Train Loss: 0.1707, Acc: 100.00% | Val Loss: 0.1169, Acc: 100.00%\n",
            "Epoch [53/100] Train Loss: 0.1502, Acc: 100.00% | Val Loss: 0.1110, Acc: 100.00%\n",
            "Epoch [54/100] Train Loss: 0.2933, Acc: 97.14% | Val Loss: 0.1012, Acc: 100.00%\n",
            "Epoch [55/100] Train Loss: 0.1494, Acc: 100.00% | Val Loss: 0.0996, Acc: 100.00%\n",
            "Epoch [56/100] Train Loss: 0.1270, Acc: 100.00% | Val Loss: 0.0955, Acc: 100.00%\n",
            "Epoch [57/100] Train Loss: 0.1036, Acc: 100.00% | Val Loss: 0.0921, Acc: 100.00%\n",
            "Epoch [58/100] Train Loss: 0.1673, Acc: 100.00% | Val Loss: 0.0910, Acc: 100.00%\n",
            "Epoch [59/100] Train Loss: 0.1688, Acc: 100.00% | Val Loss: 0.0836, Acc: 100.00%\n",
            "Epoch [60/100] Train Loss: 0.1134, Acc: 100.00% | Val Loss: 0.0776, Acc: 100.00%\n",
            "Epoch [61/100] Train Loss: 0.0986, Acc: 100.00% | Val Loss: 0.0721, Acc: 100.00%\n",
            "Epoch [62/100] Train Loss: 0.1164, Acc: 100.00% | Val Loss: 0.0695, Acc: 100.00%\n",
            "Epoch [63/100] Train Loss: 0.1242, Acc: 100.00% | Val Loss: 0.0650, Acc: 100.00%\n",
            "Epoch [64/100] Train Loss: 0.0915, Acc: 100.00% | Val Loss: 0.0626, Acc: 100.00%\n",
            "Epoch [65/100] Train Loss: 0.0828, Acc: 100.00% | Val Loss: 0.0589, Acc: 100.00%\n",
            "Epoch [66/100] Train Loss: 0.0907, Acc: 100.00% | Val Loss: 0.0575, Acc: 100.00%\n",
            "Epoch [67/100] Train Loss: 0.0733, Acc: 100.00% | Val Loss: 0.0553, Acc: 100.00%\n",
            "Epoch [68/100] Train Loss: 0.1276, Acc: 100.00% | Val Loss: 0.0524, Acc: 100.00%\n",
            "Epoch [69/100] Train Loss: 0.1001, Acc: 100.00% | Val Loss: 0.0483, Acc: 100.00%\n",
            "Epoch [70/100] Train Loss: 0.2413, Acc: 98.57% | Val Loss: 0.0434, Acc: 100.00%\n",
            "Epoch [71/100] Train Loss: 0.1063, Acc: 100.00% | Val Loss: 0.0417, Acc: 100.00%\n",
            "Epoch [72/100] Train Loss: 0.0747, Acc: 100.00% | Val Loss: 0.0413, Acc: 100.00%\n",
            "Epoch [73/100] Train Loss: 0.0637, Acc: 100.00% | Val Loss: 0.0417, Acc: 100.00%\n",
            "Epoch [74/100] Train Loss: 0.0661, Acc: 100.00% | Val Loss: 0.0422, Acc: 100.00%\n",
            "Epoch [75/100] Train Loss: 0.1501, Acc: 100.00% | Val Loss: 0.0400, Acc: 100.00%\n",
            "Epoch [76/100] Train Loss: 0.0557, Acc: 100.00% | Val Loss: 0.0393, Acc: 100.00%\n",
            "Epoch [77/100] Train Loss: 0.0518, Acc: 100.00% | Val Loss: 0.0389, Acc: 100.00%\n",
            "Epoch [78/100] Train Loss: 0.0593, Acc: 100.00% | Val Loss: 0.0389, Acc: 100.00%\n",
            "Epoch [79/100] Train Loss: 0.0496, Acc: 100.00% | Val Loss: 0.0374, Acc: 100.00%\n",
            "Epoch [80/100] Train Loss: 0.0455, Acc: 100.00% | Val Loss: 0.0381, Acc: 100.00%\n",
            "Epoch [81/100] Train Loss: 0.0498, Acc: 100.00% | Val Loss: 0.0369, Acc: 100.00%\n",
            "Epoch [82/100] Train Loss: 0.0678, Acc: 100.00% | Val Loss: 0.0356, Acc: 100.00%\n",
            "Epoch [83/100] Train Loss: 0.0672, Acc: 100.00% | Val Loss: 0.0336, Acc: 100.00%\n",
            "Epoch [84/100] Train Loss: 0.0473, Acc: 100.00% | Val Loss: 0.0326, Acc: 100.00%\n",
            "Epoch [85/100] Train Loss: 0.0496, Acc: 100.00% | Val Loss: 0.0312, Acc: 100.00%\n",
            "Epoch [86/100] Train Loss: 0.0475, Acc: 100.00% | Val Loss: 0.0315, Acc: 100.00%\n",
            "Epoch [87/100] Train Loss: 0.1053, Acc: 100.00% | Val Loss: 0.0303, Acc: 100.00%\n",
            "Epoch [88/100] Train Loss: 0.0567, Acc: 100.00% | Val Loss: 0.0293, Acc: 100.00%\n",
            "Epoch [89/100] Train Loss: 0.0483, Acc: 100.00% | Val Loss: 0.0285, Acc: 100.00%\n",
            "Epoch [90/100] Train Loss: 0.0505, Acc: 100.00% | Val Loss: 0.0276, Acc: 100.00%\n",
            "Epoch [91/100] Train Loss: 0.0295, Acc: 100.00% | Val Loss: 0.0260, Acc: 100.00%\n",
            "Epoch [92/100] Train Loss: 0.0539, Acc: 100.00% | Val Loss: 0.0258, Acc: 100.00%\n",
            "Epoch [93/100] Train Loss: 0.1397, Acc: 98.57% | Val Loss: 0.0238, Acc: 100.00%\n",
            "Epoch [94/100] Train Loss: 0.0348, Acc: 100.00% | Val Loss: 0.0233, Acc: 100.00%\n",
            "Epoch [95/100] Train Loss: 0.0316, Acc: 100.00% | Val Loss: 0.0230, Acc: 100.00%\n",
            "Epoch [96/100] Train Loss: 0.0307, Acc: 100.00% | Val Loss: 0.0225, Acc: 100.00%\n",
            "Epoch [97/100] Train Loss: 0.0258, Acc: 100.00% | Val Loss: 0.0213, Acc: 100.00%\n",
            "Epoch [98/100] Train Loss: 0.0272, Acc: 100.00% | Val Loss: 0.0221, Acc: 100.00%\n",
            "Epoch [99/100] Train Loss: 0.1586, Acc: 98.57% | Val Loss: 0.0202, Acc: 100.00%\n",
            "Epoch [100/100] Train Loss: 0.0246, Acc: 100.00% | Val Loss: 0.0197, Acc: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/Cmpt_419_Project/arm_gesture_landmark_model.pth')"
      ],
      "metadata": {
        "id": "MUpJR3or3PK-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_landmarks(landmark_vector, img_size=200):\n",
        "    \"\"\"\n",
        "    Visualize arm landmarks as a schematic image\n",
        "    landmark_vector: 18-dim array (6 points Ã— 3 coordinates)\n",
        "    img_size: Output image size in pixels\n",
        "    \"\"\"\n",
        "    # Reshape to 6 points with (x,y,z)\n",
        "    points = landmark_vector.reshape(-1, 3)\n",
        "\n",
        "    # Extract x,y coordinates (ignore z for 2D visualization)\n",
        "    xs = points[:, 0]\n",
        "    ys = 1 - points[:, 1]  # Flip Y-axis for more natural display\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Plot connections (MediaPipe arm connections)\n",
        "    connections = [\n",
        "        (0, 2),  # Left shoulder to left elbow\n",
        "        (2, 4),  # Left elbow to left wrist\n",
        "        (1, 3),  # Right shoulder to right elbow\n",
        "        (3, 5)   # Right elbow to right wrist\n",
        "    ]\n",
        "\n",
        "    # Draw connections\n",
        "    for start, end in connections:\n",
        "        ax.plot([xs[start], xs[end]], [ys[start], ys[end]],\n",
        "                linewidth=2, color='red')\n",
        "\n",
        "    # Plot landmarks\n",
        "    ax.scatter(xs, ys, s=100, c='blue', marker='o')\n",
        "\n",
        "    # Configure plot\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.axis('off')\n",
        "    plt.title(\"Arm Landmarks Schematic\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot the first sample\n",
        "if len(landmarks) > 0:\n",
        "    plot_landmarks(landmarks[65])\n",
        "else:\n",
        "    print(\"No landmarks found - check your data processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "VBpeh4is-Q1k",
        "outputId": "5be23a2b-2c2b-40ca-ec3b-4c3b5f68e3bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}