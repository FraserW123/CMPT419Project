{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fraser/.local/lib/python3.9/site-packages/numpy/_core/getlimits.py:545: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset_green/'\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87 images from 3 classes.\n",
      "Dataset size:  87\n",
      "Training set size:  69\n",
      "Validation set size:  18\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "from image_dataloader import GestureImageDataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),  # Rotate within Â±15 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Shift up to 10%\n",
    "    transforms.RandomResizedCrop(28, scale=(0.9, 1.1)),  # Slight zoom in/out\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),  # Converts to (C, H, W) where C=1 for grayscale\n",
    "])\n",
    "\n",
    "\n",
    "dataset = GestureImageDataset(data_path, transform=transform)\n",
    "\n",
    "print(\"Dataset size: \", len(dataset))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Training set size: \", len(train_dataset))\n",
    "print(\"Validation set size: \", len(val_dataset))\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Convolutional Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 1000)  # Corrected input size (3136)\n",
    "        self.fc2 = nn.Linear(1000, 3)  # Assuming 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)  # (batch, 32, 14, 14)\n",
    "        out = self.layer2(out)  # (batch, 64, 7, 7)\n",
    "        out = out.view(out.size(0), -1)  # Flatten to (batch, 3136)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Test with a random input tensor\n",
    "# model = ConvNet()\n",
    "# x = torch.randn(8, 1, 28, 28)  # Batch size = 8, Grayscale image (1, 28, 28)\n",
    "# output = model(x)\n",
    "# print(output.shape)  # Expected: (8, 26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Train Loss: 1.1135, Train Accuracy: 33.33% - Validation Loss: 1.1135, Validation Accuracy: 27.78%\n",
      "Epoch [2/100] - Train Loss: 1.1593, Train Accuracy: 33.33% - Validation Loss: 1.1593, Validation Accuracy: 27.78%\n",
      "Epoch [3/100] - Train Loss: 1.1055, Train Accuracy: 36.23% - Validation Loss: 1.1055, Validation Accuracy: 38.89%\n",
      "Epoch [4/100] - Train Loss: 1.0889, Train Accuracy: 31.88% - Validation Loss: 1.0889, Validation Accuracy: 38.89%\n",
      "Epoch [5/100] - Train Loss: 1.0938, Train Accuracy: 24.64% - Validation Loss: 1.0938, Validation Accuracy: 33.33%\n",
      "Epoch [6/100] - Train Loss: 1.0905, Train Accuracy: 33.33% - Validation Loss: 1.0905, Validation Accuracy: 38.89%\n",
      "Epoch [7/100] - Train Loss: 1.0926, Train Accuracy: 33.33% - Validation Loss: 1.0926, Validation Accuracy: 38.89%\n",
      "Epoch [8/100] - Train Loss: 1.0822, Train Accuracy: 27.54% - Validation Loss: 1.0822, Validation Accuracy: 38.89%\n",
      "Epoch [9/100] - Train Loss: 1.0838, Train Accuracy: 30.43% - Validation Loss: 1.0838, Validation Accuracy: 38.89%\n",
      "Epoch [10/100] - Train Loss: 1.0873, Train Accuracy: 31.88% - Validation Loss: 1.0873, Validation Accuracy: 38.89%\n",
      "Epoch [11/100] - Train Loss: 1.0854, Train Accuracy: 31.88% - Validation Loss: 1.0854, Validation Accuracy: 38.89%\n",
      "Epoch [12/100] - Train Loss: 1.0993, Train Accuracy: 34.78% - Validation Loss: 1.0993, Validation Accuracy: 27.78%\n",
      "Epoch [13/100] - Train Loss: 1.1232, Train Accuracy: 36.23% - Validation Loss: 1.1232, Validation Accuracy: 27.78%\n",
      "Epoch [14/100] - Train Loss: 1.1368, Train Accuracy: 34.78% - Validation Loss: 1.1368, Validation Accuracy: 27.78%\n",
      "Epoch [15/100] - Train Loss: 1.1319, Train Accuracy: 40.58% - Validation Loss: 1.1319, Validation Accuracy: 27.78%\n",
      "Epoch [16/100] - Train Loss: 1.1270, Train Accuracy: 31.88% - Validation Loss: 1.1270, Validation Accuracy: 33.33%\n",
      "Epoch [17/100] - Train Loss: 1.1188, Train Accuracy: 33.33% - Validation Loss: 1.1188, Validation Accuracy: 33.33%\n",
      "Epoch [18/100] - Train Loss: 1.1094, Train Accuracy: 33.33% - Validation Loss: 1.1094, Validation Accuracy: 33.33%\n",
      "Epoch [19/100] - Train Loss: 1.0996, Train Accuracy: 33.33% - Validation Loss: 1.0996, Validation Accuracy: 33.33%\n",
      "Epoch [20/100] - Train Loss: 1.0906, Train Accuracy: 33.33% - Validation Loss: 1.0906, Validation Accuracy: 38.89%\n",
      "Epoch [21/100] - Train Loss: 1.0733, Train Accuracy: 50.72% - Validation Loss: 1.0733, Validation Accuracy: 50.00%\n",
      "Epoch [22/100] - Train Loss: 1.0829, Train Accuracy: 47.83% - Validation Loss: 1.0829, Validation Accuracy: 50.00%\n",
      "Epoch [23/100] - Train Loss: 1.0986, Train Accuracy: 46.38% - Validation Loss: 1.0986, Validation Accuracy: 27.78%\n",
      "Epoch [24/100] - Train Loss: 1.0851, Train Accuracy: 37.68% - Validation Loss: 1.0851, Validation Accuracy: 27.78%\n",
      "Epoch [25/100] - Train Loss: 1.0822, Train Accuracy: 42.03% - Validation Loss: 1.0822, Validation Accuracy: 44.44%\n",
      "Epoch [26/100] - Train Loss: 1.0856, Train Accuracy: 42.03% - Validation Loss: 1.0856, Validation Accuracy: 33.33%\n",
      "Epoch [27/100] - Train Loss: 1.0954, Train Accuracy: 33.33% - Validation Loss: 1.0954, Validation Accuracy: 33.33%\n",
      "Epoch [28/100] - Train Loss: 1.0852, Train Accuracy: 34.78% - Validation Loss: 1.0852, Validation Accuracy: 33.33%\n",
      "Epoch [29/100] - Train Loss: 1.0888, Train Accuracy: 37.68% - Validation Loss: 1.0888, Validation Accuracy: 38.89%\n",
      "Epoch [30/100] - Train Loss: 1.0672, Train Accuracy: 40.58% - Validation Loss: 1.0672, Validation Accuracy: 44.44%\n",
      "Epoch [31/100] - Train Loss: 1.0606, Train Accuracy: 43.48% - Validation Loss: 1.0606, Validation Accuracy: 61.11%\n",
      "Epoch [32/100] - Train Loss: 1.0667, Train Accuracy: 56.52% - Validation Loss: 1.0667, Validation Accuracy: 33.33%\n",
      "Epoch [33/100] - Train Loss: 1.0665, Train Accuracy: 57.97% - Validation Loss: 1.0665, Validation Accuracy: 61.11%\n",
      "Epoch [34/100] - Train Loss: 1.0806, Train Accuracy: 46.38% - Validation Loss: 1.0806, Validation Accuracy: 38.89%\n",
      "Epoch [35/100] - Train Loss: 1.0655, Train Accuracy: 56.52% - Validation Loss: 1.0655, Validation Accuracy: 44.44%\n",
      "Epoch [36/100] - Train Loss: 1.0441, Train Accuracy: 65.22% - Validation Loss: 1.0441, Validation Accuracy: 50.00%\n",
      "Epoch [37/100] - Train Loss: 1.0369, Train Accuracy: 47.83% - Validation Loss: 1.0369, Validation Accuracy: 38.89%\n",
      "Epoch [38/100] - Train Loss: 1.0266, Train Accuracy: 49.28% - Validation Loss: 1.0266, Validation Accuracy: 55.56%\n",
      "Epoch [39/100] - Train Loss: 0.9644, Train Accuracy: 52.17% - Validation Loss: 0.9644, Validation Accuracy: 55.56%\n",
      "Epoch [40/100] - Train Loss: 1.0689, Train Accuracy: 53.62% - Validation Loss: 1.0689, Validation Accuracy: 38.89%\n",
      "Epoch [41/100] - Train Loss: 1.0349, Train Accuracy: 50.72% - Validation Loss: 1.0349, Validation Accuracy: 50.00%\n",
      "Epoch [42/100] - Train Loss: 1.0197, Train Accuracy: 55.07% - Validation Loss: 1.0197, Validation Accuracy: 55.56%\n",
      "Epoch [43/100] - Train Loss: 1.0803, Train Accuracy: 42.03% - Validation Loss: 1.0803, Validation Accuracy: 38.89%\n",
      "Epoch [44/100] - Train Loss: 1.0226, Train Accuracy: 50.72% - Validation Loss: 1.0226, Validation Accuracy: 33.33%\n",
      "Epoch [45/100] - Train Loss: 0.9622, Train Accuracy: 44.93% - Validation Loss: 0.9622, Validation Accuracy: 61.11%\n",
      "Epoch [46/100] - Train Loss: 0.9738, Train Accuracy: 52.17% - Validation Loss: 0.9738, Validation Accuracy: 55.56%\n",
      "Epoch [47/100] - Train Loss: 0.9985, Train Accuracy: 56.52% - Validation Loss: 0.9985, Validation Accuracy: 61.11%\n",
      "Epoch [48/100] - Train Loss: 1.0369, Train Accuracy: 68.12% - Validation Loss: 1.0369, Validation Accuracy: 44.44%\n",
      "Epoch [49/100] - Train Loss: 0.9350, Train Accuracy: 59.42% - Validation Loss: 0.9350, Validation Accuracy: 72.22%\n",
      "Epoch [50/100] - Train Loss: 0.9722, Train Accuracy: 62.32% - Validation Loss: 0.9722, Validation Accuracy: 61.11%\n",
      "Epoch [51/100] - Train Loss: 0.9627, Train Accuracy: 62.32% - Validation Loss: 0.9627, Validation Accuracy: 61.11%\n",
      "Epoch [52/100] - Train Loss: 0.9941, Train Accuracy: 65.22% - Validation Loss: 0.9941, Validation Accuracy: 61.11%\n",
      "Epoch [53/100] - Train Loss: 0.9238, Train Accuracy: 69.57% - Validation Loss: 0.9238, Validation Accuracy: 72.22%\n",
      "Epoch [54/100] - Train Loss: 0.8808, Train Accuracy: 66.67% - Validation Loss: 0.8808, Validation Accuracy: 66.67%\n",
      "Epoch [55/100] - Train Loss: 0.8903, Train Accuracy: 63.77% - Validation Loss: 0.8903, Validation Accuracy: 77.78%\n",
      "Epoch [56/100] - Train Loss: 0.8859, Train Accuracy: 56.52% - Validation Loss: 0.8859, Validation Accuracy: 55.56%\n",
      "Epoch [57/100] - Train Loss: 0.9814, Train Accuracy: 60.87% - Validation Loss: 0.9814, Validation Accuracy: 55.56%\n",
      "Epoch [58/100] - Train Loss: 0.8572, Train Accuracy: 59.42% - Validation Loss: 0.8572, Validation Accuracy: 72.22%\n",
      "Epoch [59/100] - Train Loss: 0.8684, Train Accuracy: 68.12% - Validation Loss: 0.8684, Validation Accuracy: 72.22%\n",
      "Epoch [60/100] - Train Loss: 0.8900, Train Accuracy: 72.46% - Validation Loss: 0.8900, Validation Accuracy: 66.67%\n",
      "Epoch [61/100] - Train Loss: 0.8242, Train Accuracy: 73.91% - Validation Loss: 0.8242, Validation Accuracy: 83.33%\n",
      "Epoch [62/100] - Train Loss: 0.7961, Train Accuracy: 76.81% - Validation Loss: 0.7961, Validation Accuracy: 61.11%\n",
      "Epoch [63/100] - Train Loss: 0.8498, Train Accuracy: 53.62% - Validation Loss: 0.8498, Validation Accuracy: 50.00%\n",
      "Epoch [64/100] - Train Loss: 0.9062, Train Accuracy: 60.87% - Validation Loss: 0.9062, Validation Accuracy: 61.11%\n",
      "Epoch [65/100] - Train Loss: 0.8333, Train Accuracy: 79.71% - Validation Loss: 0.8333, Validation Accuracy: 77.78%\n",
      "Epoch [66/100] - Train Loss: 0.7458, Train Accuracy: 66.67% - Validation Loss: 0.7458, Validation Accuracy: 88.89%\n",
      "Epoch [67/100] - Train Loss: 0.7703, Train Accuracy: 76.81% - Validation Loss: 0.7703, Validation Accuracy: 72.22%\n",
      "Epoch [68/100] - Train Loss: 0.7578, Train Accuracy: 62.32% - Validation Loss: 0.7578, Validation Accuracy: 66.67%\n",
      "Epoch [69/100] - Train Loss: 0.7287, Train Accuracy: 68.12% - Validation Loss: 0.7287, Validation Accuracy: 72.22%\n",
      "Epoch [70/100] - Train Loss: 0.6770, Train Accuracy: 76.81% - Validation Loss: 0.6770, Validation Accuracy: 83.33%\n",
      "Epoch [71/100] - Train Loss: 0.6656, Train Accuracy: 75.36% - Validation Loss: 0.6656, Validation Accuracy: 88.89%\n",
      "Epoch [72/100] - Train Loss: 0.6241, Train Accuracy: 73.91% - Validation Loss: 0.6241, Validation Accuracy: 94.44%\n",
      "Epoch [73/100] - Train Loss: 0.6261, Train Accuracy: 81.16% - Validation Loss: 0.6261, Validation Accuracy: 77.78%\n",
      "Epoch [74/100] - Train Loss: 0.6302, Train Accuracy: 79.71% - Validation Loss: 0.6302, Validation Accuracy: 83.33%\n",
      "Epoch [75/100] - Train Loss: 0.7472, Train Accuracy: 79.71% - Validation Loss: 0.7472, Validation Accuracy: 61.11%\n",
      "Epoch [76/100] - Train Loss: 0.6656, Train Accuracy: 73.91% - Validation Loss: 0.6656, Validation Accuracy: 88.89%\n",
      "Epoch [77/100] - Train Loss: 0.5326, Train Accuracy: 75.36% - Validation Loss: 0.5326, Validation Accuracy: 94.44%\n",
      "Epoch [78/100] - Train Loss: 0.5159, Train Accuracy: 82.61% - Validation Loss: 0.5159, Validation Accuracy: 94.44%\n",
      "Epoch [79/100] - Train Loss: 0.5776, Train Accuracy: 81.16% - Validation Loss: 0.5776, Validation Accuracy: 94.44%\n",
      "Epoch [80/100] - Train Loss: 0.6132, Train Accuracy: 81.16% - Validation Loss: 0.6132, Validation Accuracy: 88.89%\n",
      "Epoch [81/100] - Train Loss: 0.5471, Train Accuracy: 84.06% - Validation Loss: 0.5471, Validation Accuracy: 94.44%\n",
      "Epoch [82/100] - Train Loss: 0.5988, Train Accuracy: 86.96% - Validation Loss: 0.5988, Validation Accuracy: 88.89%\n",
      "Epoch [83/100] - Train Loss: 0.4721, Train Accuracy: 85.51% - Validation Loss: 0.4721, Validation Accuracy: 94.44%\n",
      "Epoch [84/100] - Train Loss: 0.4854, Train Accuracy: 81.16% - Validation Loss: 0.4854, Validation Accuracy: 94.44%\n",
      "Epoch [85/100] - Train Loss: 0.4958, Train Accuracy: 86.96% - Validation Loss: 0.4958, Validation Accuracy: 94.44%\n",
      "Epoch [86/100] - Train Loss: 0.6341, Train Accuracy: 86.96% - Validation Loss: 0.6341, Validation Accuracy: 77.78%\n",
      "Epoch [87/100] - Train Loss: 0.4742, Train Accuracy: 81.16% - Validation Loss: 0.4742, Validation Accuracy: 94.44%\n",
      "Epoch [88/100] - Train Loss: 0.3752, Train Accuracy: 85.51% - Validation Loss: 0.3752, Validation Accuracy: 94.44%\n",
      "Epoch [89/100] - Train Loss: 0.5690, Train Accuracy: 81.16% - Validation Loss: 0.5690, Validation Accuracy: 88.89%\n",
      "Epoch [90/100] - Train Loss: 0.4508, Train Accuracy: 81.16% - Validation Loss: 0.4508, Validation Accuracy: 100.00%\n",
      "Epoch [91/100] - Train Loss: 0.5196, Train Accuracy: 88.41% - Validation Loss: 0.5196, Validation Accuracy: 83.33%\n",
      "Epoch [92/100] - Train Loss: 0.4189, Train Accuracy: 85.51% - Validation Loss: 0.4189, Validation Accuracy: 94.44%\n",
      "Epoch [93/100] - Train Loss: 0.3975, Train Accuracy: 95.65% - Validation Loss: 0.3975, Validation Accuracy: 83.33%\n",
      "Epoch [94/100] - Train Loss: 0.5268, Train Accuracy: 79.71% - Validation Loss: 0.5268, Validation Accuracy: 66.67%\n",
      "Epoch [95/100] - Train Loss: 0.3890, Train Accuracy: 85.51% - Validation Loss: 0.3890, Validation Accuracy: 100.00%\n",
      "Epoch [96/100] - Train Loss: 0.3809, Train Accuracy: 84.06% - Validation Loss: 0.3809, Validation Accuracy: 100.00%\n",
      "Epoch [97/100] - Train Loss: 0.4006, Train Accuracy: 85.51% - Validation Loss: 0.4006, Validation Accuracy: 94.44%\n",
      "Epoch [98/100] - Train Loss: 0.3516, Train Accuracy: 91.30% - Validation Loss: 0.3516, Validation Accuracy: 94.44%\n",
      "Epoch [99/100] - Train Loss: 0.4445, Train Accuracy: 86.96% - Validation Loss: 0.4445, Validation Accuracy: 88.89%\n",
      "Epoch [100/100] - Train Loss: 0.7165, Train Accuracy: 95.65% - Validation Loss: 0.7165, Validation Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # Compute training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    # Compute overall training accuracy\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_acc.append(train_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_acc.append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
    "          f'Train Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}% - '\n",
    "          f'Validation Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image(model, image_path, device):\n",
    "    \"\"\"\n",
    "    Given a trained model and an image path, predict the label of the image.\n",
    "    \"\"\"\n",
    "    # Define the same transformations used during training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(),  # Ensure image is grayscale (if applicable)\n",
    "        transforms.Resize((28, 28)),  # Resize to match model input size\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "    ])\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension: (1, 1, 28, 28)\n",
    "\n",
    "    # Move to device (CPU/GPU)\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)  # Get predicted class\n",
    "\n",
    "    return predicted.item()  # Return the predicted label\n",
    "\n",
    "# Example Usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "image_path = \"unused_data/right6.jpg\"  # Replace with your image path\n",
    "predicted_label = predict_image(model, image_path, device)\n",
    "\n",
    "print(f\"Predicted label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
